{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sent1 = \"Calculated solution molecular masses are 213 kDa for PROTEIN, 73 kDa for PROTEIN1, and 186 kDa for both.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sent2 = \"The recombinant material is similar to authentic PROTEIN from Acanthamoeba-based on fluorescence monitored urea denaturation, circular dichroism, actin-nucleotide exchange rate and the Kd for rabbit PROTEIN1.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Pratik\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import re\n",
    "import logging\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import transformers\n",
    "import warnings\n",
    "import torch\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "config = AutoConfig.from_pretrained(\"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/biobert_v1.1_pubmed/config.json\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"monologg/biobert_v1.1_pubmed\")\n",
    "model = AutoModel.from_pretrained(\"monologg/biobert_v1.1_pubmed\",config=config)\n",
    "max_len= 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print (device)\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize\n",
    "stopwords=['introduction','document','begin','end','amssymb','documentclass','wasysym','oddsidemargin','12pt','69pt','minimal','mathrsfs','amsbsy','background','abstract','title:','introduction:','background:','abstract:','title','doi', 'preprint', 'copyright', 'peer', 'reviewed', 'org', 'https', 'et', 'al', 'author', 'figure', \n",
    "    'rights', 'reserved','conclusion', 'permission', 'used','al.', 'using', 'biorxiv', 'medrxiv', 'license', 'Fig', 'Fig.','Figs','Figs.','fig', 'fig.', 'et','al','day',\n",
    "    'al.', 'elsevier', 'PMC', 'CZI', 'www','com','abstract:','introduction','that','because','of','title','abstract','cite',\"Wang\",\"may\",\n",
    "    \"Devi\",\"Zhang\",\"Li\",\"Abstract\",\"Liu\",\"Singh\",\"Yang\",\"Kumar\",\"Wu\",\"Xu\",\"Smith\",\"Johnson\",\"Williams\",\"Brown\",\"Jones\",\"Miller\",\"Davis\",\"Wilson\", \"Anderson\", \"Taylor\",\"usepackage\",\"amsfonts\",\"amsmath\",\"amsby\",\"setlength\",\"upgreek\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = re.sub(r\"\"\"\n",
    "               [,@#;:?!()&$]+  # Accept one or more copies of punctuation\n",
    "               \\ *           # plus zero or more copies of a space,\n",
    "               \"\"\",\n",
    "               \" \",          # and replace it with a single space\n",
    "               Sent1, flags=re.VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Calculated solution molecular masses are 213 kDa for PROTEIN 73 kDa for PROTEIN1 and 186 kDa for both.'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Calculated', 'solution', 'molecular', 'masses', 'are', '213', 'kDa', 'for', 'PROTEIN', '73', 'kDa', 'for', 'PROTEIN1', 'and', '186', 'kDa', 'for', 'both.']\n"
     ]
    }
   ],
   "source": [
    "words=clean.split()\n",
    "print (words)\n",
    "resultwords= [word for word in words if word.lower() not in stopwords and word not in numbers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Calculated',\n",
       " 'solution',\n",
       " 'molecular',\n",
       " 'masses',\n",
       " 'are',\n",
       " '213',\n",
       " 'kDa',\n",
       " 'for',\n",
       " 'PROTEIN',\n",
       " '73',\n",
       " 'kDa',\n",
       " 'for',\n",
       " 'PROTEIN1',\n",
       " 'and',\n",
       " '186',\n",
       " 'kDa',\n",
       " 'for',\n",
       " 'both.']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  101, 11917, 24029,  1181,  5072,  9546, 12980,  1132, 21640,\n",
       "          180,  2137,  1161,  1111, 11629, 14697, 27514,  2249,  5766,\n",
       "          180,  2137,  1161,  1111, 11629, 14697, 27514,  2249,  1475,\n",
       "         1105, 21331,   180,  2137,  1161,  1111,  1241,   119,   102,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = ' '.join([i for i in resultwords])\n",
    "# Create sentence tokens\n",
    "ls = sent_tokenize(text)\n",
    "l=[s for s in ls if len(s)>=50]\n",
    "tokenized = [tokenizer.encode(x, add_special_tokens=True,truncation=True) for x in l]\n",
    "padded = np.array([x + [0]*(max_len-len(x)) for x in tokenized])\n",
    "padded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of the token embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_mask = np.where(padded != 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512]) torch.Size([1, 512])\n"
     ]
    }
   ],
   "source": [
    "input_ids = torch.tensor(padded).to(torch.int64).to(device)\n",
    "attention_mask = torch.tensor(attention_mask).to(torch.int64).to(device)\n",
    "print (input_ids.size(), attention_mask.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs, cls = model(input_ids, attention_mask=attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 768]) torch.Size([1, 768])\n"
     ]
    }
   ],
   "source": [
    "print (outputs.shape, cls.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BioBERT embedding of a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-5.0766e-02,  2.6324e-02,  9.6780e-01, -1.0000e+00,  9.9999e-01,\n",
       "          1.3029e-01,  1.6034e-01,  9.4219e-01, -5.4331e-02,  6.8003e-02,\n",
       "          8.4922e-01,  9.9992e-01, -1.1338e-02, -8.8088e-01, -6.8710e-02,\n",
       "          8.0648e-03,  1.0000e+00,  4.1214e-02, -9.9626e-01, -1.4326e-01,\n",
       "          7.0472e-02, -9.7107e-01, -3.0532e-02,  9.9108e-01, -1.0616e-01,\n",
       "         -5.8385e-02,  9.9988e-01,  9.9624e-01, -1.7464e-02, -1.9913e-01,\n",
       "          1.3201e-02, -1.0000e+00,  9.9549e-01, -9.9993e-01,  8.3575e-02,\n",
       "          1.3578e-02, -3.6289e-02,  6.6727e-02,  7.9160e-01, -9.9875e-01,\n",
       "          1.0049e-01, -5.9257e-01,  8.5778e-02,  3.7033e-02,  9.9898e-01,\n",
       "          5.1273e-03, -1.4944e-02, -8.1968e-03,  1.8911e-02,  3.4958e-01,\n",
       "          1.5714e-01,  9.7260e-01,  6.5083e-01,  9.9824e-01,  9.9967e-01,\n",
       "         -8.7032e-02,  1.0000e+00,  5.6373e-02,  9.0991e-01, -1.1657e-01,\n",
       "          9.9999e-01, -1.8076e-02, -6.5881e-02,  1.8510e-01,  8.9966e-02,\n",
       "         -1.0804e-01, -8.5976e-01, -9.1498e-02, -6.5500e-02,  5.0610e-02,\n",
       "          2.6808e-02,  3.5671e-02,  9.9701e-01, -9.9976e-01,  8.5322e-02,\n",
       "         -3.4275e-02, -5.0134e-02, -9.7843e-01,  9.9925e-01,  9.9974e-01,\n",
       "         -7.2652e-02, -9.9810e-01,  1.0000e+00,  7.6759e-02, -5.4135e-02,\n",
       "          5.9603e-02,  6.3628e-01, -9.9985e-01, -5.4257e-02,  8.2110e-02,\n",
       "          8.1829e-01, -9.9994e-01,  6.4366e-02, -4.8621e-01,  9.9435e-01,\n",
       "         -1.2537e-01,  1.1740e-01, -4.7236e-02,  6.0861e-01, -9.8607e-02,\n",
       "          4.5658e-02,  9.9379e-01,  2.3275e-02,  8.0994e-01, -3.1955e-02,\n",
       "         -3.8284e-02,  7.3430e-02,  3.5159e-02, -2.0966e-02,  2.4831e-03,\n",
       "         -9.3244e-02,  8.3548e-02, -1.3916e-01, -1.1061e-01,  9.8381e-01,\n",
       "          4.7785e-01,  9.9999e-01,  8.3603e-01, -5.3762e-02,  9.9779e-01,\n",
       "         -3.0850e-02,  9.8744e-01,  9.9989e-01,  2.0054e-02, -7.6441e-02,\n",
       "          2.3791e-02, -3.1901e-02,  9.9929e-01, -1.6388e-01,  3.9525e-02,\n",
       "         -9.3564e-04, -9.9990e-01, -9.9917e-01,  9.9822e-01,  3.3938e-02,\n",
       "          9.9982e-01, -9.9977e-01,  9.4514e-01, -9.8579e-01, -4.4602e-02,\n",
       "         -8.6931e-01, -2.2827e-02, -9.8336e-01, -9.1464e-02,  9.9989e-01,\n",
       "         -2.8404e-02, -9.9889e-01, -1.5622e-01,  7.1334e-03,  8.1955e-02,\n",
       "         -1.6090e-01, -8.5276e-02,  8.7584e-02,  9.9305e-01,  8.1553e-01,\n",
       "          9.9898e-01,  9.9863e-01,  3.9322e-02, -2.1679e-01,  9.3752e-01,\n",
       "         -6.3416e-03, -9.9959e-01, -2.0423e-01, -9.9925e-01,  9.9312e-01,\n",
       "          9.9987e-01,  1.4434e-01,  9.4683e-01,  9.9961e-01, -7.4294e-02,\n",
       "          1.2998e-01, -9.1871e-02, -4.9455e-02,  5.8753e-01, -2.6490e-02,\n",
       "         -6.4650e-03,  2.7315e-02,  3.7582e-02, -9.9980e-01, -3.2765e-03,\n",
       "          7.2250e-01, -4.1520e-02, -4.8664e-02, -8.6041e-01, -1.0000e+00,\n",
       "          4.7514e-02, -9.9887e-01, -9.5307e-02,  1.7654e-01,  1.8612e-01,\n",
       "          2.0032e-01,  9.9969e-01, -6.2241e-01, -1.5037e-01, -1.2754e-01,\n",
       "          8.6998e-02,  9.9723e-01,  6.5071e-03,  9.9924e-01,  8.9560e-02,\n",
       "         -9.9998e-01, -8.9663e-01,  3.5645e-02, -9.8457e-02,  4.2611e-02,\n",
       "          5.1391e-02,  4.3095e-02, -9.5302e-02, -6.2850e-01, -9.7028e-01,\n",
       "         -8.0676e-01,  2.5802e-02,  1.5177e-01, -1.1494e-01,  1.4979e-03,\n",
       "          1.4225e-01,  1.6385e-02,  5.4791e-02, -5.1485e-03,  9.9879e-01,\n",
       "         -9.9991e-01, -6.1970e-02, -6.3025e-02, -9.9993e-01, -9.9999e-01,\n",
       "          1.0161e-01, -3.8618e-02, -2.6822e-01, -3.6852e-02, -6.8348e-01,\n",
       "          1.1269e-02,  9.8221e-01,  1.0000e+00,  5.3698e-02, -6.1960e-02,\n",
       "         -9.9849e-01,  8.7917e-01,  1.2391e-01,  7.5551e-02,  6.4285e-02,\n",
       "         -5.9153e-02,  3.0557e-03,  5.3461e-02, -8.5271e-01, -1.2922e-02,\n",
       "          1.6447e-02, -7.5842e-01,  1.0667e-01, -1.9360e-01, -4.2102e-01,\n",
       "          4.0393e-02,  5.5138e-01, -1.3122e-01,  9.9998e-01, -9.9843e-01,\n",
       "          7.0466e-01,  9.6798e-01, -9.9993e-01, -1.8218e-02,  4.4390e-01,\n",
       "          7.0897e-02, -9.9668e-01,  1.4986e-01,  7.1552e-02, -1.4626e-02,\n",
       "         -1.5838e-02,  9.9998e-01,  1.2573e-01,  5.5188e-02,  2.1201e-01,\n",
       "         -9.9694e-01, -4.4319e-02,  6.1786e-03,  9.9999e-01,  9.5460e-01,\n",
       "         -1.8695e-01,  6.9401e-02,  8.3798e-02, -1.0000e+00, -9.3355e-01,\n",
       "          2.0436e-01,  9.2532e-01, -1.0000e+00,  7.0977e-02,  9.9905e-01,\n",
       "          9.5955e-01,  1.0099e-01, -9.9961e-01, -5.2147e-02, -9.9990e-01,\n",
       "          2.9622e-02,  2.4754e-02, -2.4503e-02,  1.0009e-02,  6.1635e-02,\n",
       "         -2.1853e-02,  9.9907e-01,  9.9848e-01,  3.5234e-02, -1.5314e-01,\n",
       "         -1.9215e-02, -1.0000e+00, -9.7673e-01,  1.5791e-02,  5.9320e-02,\n",
       "         -9.8789e-01,  1.0000e+00, -9.9051e-01,  9.9461e-01,  9.9713e-01,\n",
       "          9.1142e-01, -4.2053e-02, -1.3641e-02, -9.9906e-01,  1.0153e-02,\n",
       "          9.9338e-01,  9.9947e-01,  3.7504e-02,  4.6113e-02,  9.3665e-01,\n",
       "         -4.7201e-02, -3.5171e-02, -2.0395e-03, -7.7662e-02, -3.6589e-03,\n",
       "          3.1628e-03,  6.6564e-01,  5.8686e-02, -8.7195e-01,  6.1881e-01,\n",
       "         -3.8861e-02, -1.2622e-01, -5.6368e-01,  1.9302e-02,  1.1570e-01,\n",
       "          2.1081e-02, -2.1633e-01,  3.7763e-02, -1.0118e-01,  1.4089e-02,\n",
       "         -9.4454e-02,  5.9054e-01, -8.1250e-02,  7.7699e-01,  3.3696e-03,\n",
       "         -9.8888e-01,  9.9956e-01,  8.8144e-02, -3.8386e-01,  7.9823e-01,\n",
       "          9.9356e-01, -9.9920e-01, -5.2400e-03, -2.2013e-02,  1.6353e-01,\n",
       "          3.8565e-02,  1.0000e+00, -4.1829e-01,  3.9957e-01,  4.1897e-01,\n",
       "         -1.7818e-02,  7.6749e-03, -1.0885e-03, -2.5281e-01, -1.3465e-01,\n",
       "          5.7475e-01, -7.6944e-02,  9.9282e-01, -7.1090e-01,  8.7086e-02,\n",
       "          5.1693e-02, -6.6236e-01,  6.0819e-02, -9.4351e-02, -4.6304e-01,\n",
       "         -5.3184e-02, -9.1692e-01,  4.7662e-02, -4.3994e-01, -9.8782e-02,\n",
       "          9.9923e-01, -3.0064e-02, -6.3943e-02,  3.5287e-02,  2.0286e-01,\n",
       "          9.9994e-01, -9.9997e-01,  1.2028e-01,  9.9991e-01,  4.6078e-02,\n",
       "         -3.9943e-02, -4.1271e-02, -7.9903e-01,  5.0396e-02, -1.2555e-01,\n",
       "         -9.9598e-01, -2.9204e-02, -3.8188e-02, -3.7354e-02, -5.8899e-03,\n",
       "         -8.9189e-02, -6.0855e-02,  8.7224e-01,  1.2649e-01, -3.7037e-02,\n",
       "          9.8956e-02,  8.2842e-03, -1.3783e-01,  3.2615e-02,  3.1279e-02,\n",
       "          2.0804e-02, -8.6969e-02,  1.8626e-01,  5.8710e-02,  8.9928e-02,\n",
       "          9.9048e-01,  5.2261e-02, -9.9893e-01,  9.4461e-01, -6.0268e-03,\n",
       "         -9.9333e-01,  1.0500e-01, -9.9811e-01,  1.0000e+00,  9.9670e-01,\n",
       "          6.7062e-01,  7.0187e-01, -9.9928e-01, -9.9724e-01, -4.8376e-01,\n",
       "          1.5749e-02,  4.4605e-02,  2.9766e-02,  8.3121e-01, -5.5013e-02,\n",
       "         -5.0744e-02, -2.3211e-02,  1.2072e-01, -2.0428e-02,  8.3181e-01,\n",
       "          5.0298e-01, -9.9924e-01, -1.2497e-01,  9.3997e-01,  6.4770e-01,\n",
       "         -9.0614e-01,  1.7126e-01, -3.2241e-01,  1.7448e-02, -9.7620e-02,\n",
       "          3.1349e-02, -1.5824e-01, -9.6062e-02, -9.5837e-01, -6.7328e-02,\n",
       "         -1.0215e-01, -7.0484e-02, -4.5949e-02,  1.2847e-02,  9.1822e-01,\n",
       "         -7.0220e-01,  1.5649e-02, -4.7016e-02, -4.7779e-01, -1.7983e-01,\n",
       "         -9.8492e-01, -5.4876e-01, -9.0859e-01, -1.8386e-01,  1.4091e-02,\n",
       "         -9.9887e-01,  5.4431e-02,  9.7726e-01,  9.9252e-01,  9.9897e-01,\n",
       "         -3.6758e-02, -7.8452e-02,  3.4616e-03, -6.4269e-02, -9.9817e-01,\n",
       "         -1.1359e-01,  6.8975e-02,  7.5052e-02, -4.4927e-01,  1.5894e-01,\n",
       "          8.2342e-02,  8.3374e-01, -9.9879e-01,  9.9581e-01, -1.2413e-01,\n",
       "         -2.0823e-02, -2.2716e-02, -2.0274e-02,  3.3890e-02,  1.0826e-01,\n",
       "         -9.9953e-01,  1.0782e-01,  1.0000e+00,  9.5543e-01,  9.8950e-01,\n",
       "          9.4465e-01, -6.4808e-01, -9.4239e-03,  1.3548e-02, -9.9853e-01,\n",
       "         -9.9191e-01,  6.4389e-02, -1.0150e-02, -9.9950e-01,  9.7799e-01,\n",
       "         -9.9172e-01,  1.0315e-01,  8.9540e-03,  9.9897e-01,  9.9954e-01,\n",
       "         -4.4933e-02, -9.9921e-01, -9.9960e-01,  6.6300e-01,  8.8008e-02,\n",
       "         -3.0137e-02,  1.0617e-01,  3.7310e-02,  6.2800e-03, -2.2456e-02,\n",
       "          9.4748e-01,  8.8644e-02,  1.4980e-01,  2.9297e-01,  9.9996e-01,\n",
       "         -2.9491e-02, -9.9099e-01,  2.8181e-01, -7.6210e-02, -5.0902e-01,\n",
       "          1.0912e-01,  9.9662e-01, -4.5459e-02,  7.4365e-01,  9.9568e-01,\n",
       "         -9.9917e-01,  9.7572e-01, -9.9946e-01,  6.9099e-01,  9.9895e-01,\n",
       "         -1.0000e+00, -2.1923e-02, -1.0000e+00, -7.9489e-01,  2.4138e-02,\n",
       "         -1.8910e-02,  5.5563e-02,  8.0193e-01, -1.0000e+00, -9.9949e-01,\n",
       "          2.0533e-02, -5.0395e-01, -9.5373e-01,  8.6125e-01, -1.2064e-02,\n",
       "          5.6952e-02,  1.1292e-02, -6.9450e-02, -8.3208e-02, -4.2160e-01,\n",
       "          9.9918e-01, -3.4825e-02,  2.4086e-01, -1.0000e+00,  9.9705e-01,\n",
       "         -2.3174e-01, -1.1304e-01,  1.0000e+00,  2.5352e-02, -8.1341e-03,\n",
       "         -3.7232e-02, -9.9999e-01, -7.3848e-02,  7.5696e-03, -9.1485e-01,\n",
       "          7.4229e-01, -8.1499e-02,  6.6935e-02, -6.5420e-02, -9.1677e-02,\n",
       "         -9.8661e-01, -8.4428e-02, -9.9998e-01,  9.9999e-01, -9.4561e-01,\n",
       "          4.6612e-02,  5.3184e-02, -4.0245e-03,  7.5584e-02,  9.7098e-01,\n",
       "          1.0000e+00, -9.9629e-01, -7.1159e-02,  1.0000e+00,  2.1617e-02,\n",
       "         -8.3019e-02, -9.9996e-01, -8.9584e-03, -6.5568e-01, -3.1215e-03,\n",
       "          1.0000e+00, -1.2151e-03,  4.4106e-02,  9.9976e-01, -1.0000e+00,\n",
       "         -8.0129e-01,  1.0459e-01, -2.3722e-02, -9.9995e-02, -1.0000e+00,\n",
       "         -5.1291e-02, -9.1516e-01,  3.4394e-02, -9.9999e-01,  9.9647e-01,\n",
       "         -1.0000e+00,  1.4833e-01,  9.9993e-01, -7.6104e-01,  9.9887e-01,\n",
       "          3.0837e-02, -1.2294e-02,  6.9479e-02, -9.9991e-01,  5.2908e-01,\n",
       "          6.0599e-02,  5.5290e-02, -9.9342e-01, -8.0346e-01, -2.4641e-02,\n",
       "          4.8581e-01, -9.7375e-01, -7.8918e-03, -3.7748e-01,  1.1110e-02,\n",
       "         -8.1941e-02, -7.1479e-02,  2.3083e-02, -7.5934e-01,  1.6611e-02,\n",
       "         -1.2471e-01,  6.9000e-02,  5.3166e-02,  4.6108e-02, -8.7054e-02,\n",
       "          9.9041e-01, -1.0000e+00, -5.7251e-02, -9.9979e-01,  7.2430e-02,\n",
       "          5.4010e-02, -2.3295e-02,  1.8890e-02, -7.4637e-02, -1.1108e-02,\n",
       "         -9.9919e-01,  1.0000e+00, -9.9998e-01, -9.9997e-01,  9.9996e-01,\n",
       "          3.9632e-02, -9.8338e-01,  5.3046e-02, -6.2131e-02,  2.7223e-02,\n",
       "          1.2605e-02,  1.7010e-01, -2.9618e-02, -5.5421e-02, -9.8268e-01,\n",
       "          7.6206e-01, -1.1187e-01,  3.6873e-03,  9.6902e-02,  2.8649e-02,\n",
       "         -9.5784e-01,  1.0000e+00,  1.0000e+00,  9.9610e-01, -9.9971e-01,\n",
       "         -3.5557e-02, -3.9249e-02,  9.9997e-01,  3.7615e-02,  5.2798e-02,\n",
       "          9.9400e-01,  9.8021e-01,  9.1660e-03, -6.3770e-01,  1.4711e-02,\n",
       "          9.0981e-03,  1.3453e-01,  1.3120e-02, -9.3833e-01, -9.9954e-01,\n",
       "         -5.8943e-02, -9.9909e-01, -9.8491e-01,  9.7559e-01,  1.0897e-01,\n",
       "          1.0000e+00, -5.3832e-02,  1.2151e-01,  1.3520e-01, -5.4723e-01,\n",
       "         -9.9909e-01, -5.9910e-02, -9.9460e-01, -1.3173e-01, -9.9953e-01,\n",
       "         -9.9999e-01, -4.4352e-02,  4.0660e-02, -9.8289e-01,  8.1264e-02,\n",
       "          6.1393e-02, -9.9129e-01, -7.7514e-01, -9.9956e-01,  5.6116e-01,\n",
       "         -8.1655e-01, -9.0109e-01,  1.0205e-02,  5.1239e-01,  3.6654e-02,\n",
       "         -6.2117e-02, -3.0694e-01,  9.4598e-01,  4.1290e-01, -6.5661e-02,\n",
       "          9.6934e-02, -1.8234e-01, -9.9917e-01, -5.7086e-01, -1.0000e+00,\n",
       "          9.9250e-01, -1.0000e+00,  1.7434e-02,  9.9999e-01,  9.9999e-01,\n",
       "         -2.2392e-03, -9.9994e-01,  9.9938e-01, -2.3018e-02,  1.0000e+00,\n",
       "          1.1612e-01, -9.9760e-01, -9.9988e-01,  2.2624e-02,  8.0665e-02,\n",
       "          1.0000e+00,  3.1684e-02,  7.0464e-01, -7.4091e-02, -5.1843e-02,\n",
       "          1.7478e-01,  3.0365e-03, -2.6942e-03, -2.0206e-01,  2.2180e-02,\n",
       "          9.8933e-01, -5.2147e-02,  1.0000e+00]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
